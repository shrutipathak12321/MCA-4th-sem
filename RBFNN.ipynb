{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'rbf_keras'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/PetraVidnerova/rbf_keras.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training files: 40\n",
      "Number of testing files: 11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to split dataset into train and test sets\n",
    "def split_dataset(image_dir, gt_dir, test_size=0.2, random_state=42):\n",
    "    # Get list of image filenames\n",
    "    image_filenames = sorted(os.listdir(image_dir))\n",
    "    \n",
    "    # Get corresponding list of ground truth filenames\n",
    "    gt_filenames = sorted(os.listdir(gt_dir))\n",
    "    \n",
    "    # Split filenames into train and test sets\n",
    "    image_filenames_train, image_filenames_test, gt_filenames_train, gt_filenames_test = train_test_split(\n",
    "        image_filenames, gt_filenames, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    return (image_filenames_train, gt_filenames_train), (image_filenames_test, gt_filenames_test)\n",
    "\n",
    "# Example usage:\n",
    "image_dir = r\"Skullstriped2\\\\t1_icbm_normal_1mm_pn9_rf20\\\\pgm\"\n",
    "gt_dir = r\"volumes2\\\\phantom_1.0mm_normal_crisp\"\n",
    "test_size = 0.2  # 40% of the data will be used for testing\n",
    "random_state = 42  # Random seed for reproducibility\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "(train_files, train_gt_files), (test_files, test_gt_files) = split_dataset(image_dir, gt_dir, test_size, random_state)\n",
    "\n",
    "train_dir = 'Skullstriped2/t1_icbm_normal_1mm_pn9_rf20/train'\n",
    "test_dir = 'Skullstriped2/t1_icbm_normal_1mm_pn9_rf20/test'\n",
    "train_gt_dir = 'Skullstriped2/t1_icbm_normal_1mm_pn9_rf20/train_masks'\n",
    "test_gt_dir = 'Skullstriped2/t1_icbm_normal_1mm_pn9_rf20/test_masks'\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "os.makedirs(train_gt_dir, exist_ok=True)\n",
    "os.makedirs(test_gt_dir, exist_ok=True)\n",
    "\n",
    "# Copy train files to train directory\n",
    "for file_name, gt_file_name in zip(train_files, train_gt_files):\n",
    "    shutil.copyfile(os.path.join(image_dir, file_name), os.path.join(train_dir, file_name))\n",
    "    shutil.copyfile(os.path.join(gt_dir, gt_file_name), os.path.join(train_gt_dir, gt_file_name))\n",
    "\n",
    "# Copy test files to test directory\n",
    "for file_name, gt_file_name in zip(test_files, test_gt_files):\n",
    "    shutil.copyfile(os.path.join(image_dir, file_name), os.path.join(test_dir, file_name))\n",
    "    shutil.copyfile(os.path.join(gt_dir, gt_file_name), os.path.join(test_gt_dir, gt_file_name))\n",
    "\n",
    "# Display the number of files in each split\n",
    "print(\"Number of training files:\", len(train_files))\n",
    "print(\"Number of testing files:\", len(test_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_pgm(filename):\n",
    "    \"\"\"\n",
    "    Reads a PGM file and returns the image data as a 2D list.\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Skip comments\n",
    "        magic_number = f.readline().strip()\n",
    "        if magic_number != b'P2':\n",
    "            raise ValueError(\"Not a PGM file\")\n",
    "        while True:\n",
    "            line = f.readline().decode('utf-8').strip()\n",
    "            if not line.startswith('#'):\n",
    "                break\n",
    "\n",
    "        # Read the header\n",
    "        width, height = map(int, line.split())\n",
    "        max_val = int(f.readline())\n",
    "\n",
    "        # Read the image data\n",
    "        pixel_values = []\n",
    "        for _ in range(height):\n",
    "            row = map(int, f.readline().split())\n",
    "            pixel_values.extend(row)\n",
    "            \n",
    "        max_value = max(pixel_values)\n",
    "        # print(max_value)\n",
    "         # Normalize pixel values to range [0, 1]\n",
    "        pixel_values = [value / max_value for value in pixel_values]\n",
    "\n",
    "        return pixel_values\n",
    "\n",
    "def read_pgm_files_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Reads all PGM files from a folder and returns their data as a list of pixel value lists.\n",
    "    \"\"\"\n",
    "    pgm_files_pixel_values = []\n",
    "    for i, filename in enumerate(os.listdir(folder_path)):\n",
    "        if filename.endswith('.pgm'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            pixel_values = read_pgm(file_path)\n",
    "            pgm_files_pixel_values.append(pixel_values)\n",
    "    return pgm_files_pixel_values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "#folder_path = 'volumes/t1_icbm_normal_1mm_pn0_rf0/train'\n",
    "folder_path = 'Skullstriped2/t1_icbm_normal_1mm_pn9_rf20/train'\n",
    "pgm_files_pixel_values = read_pgm_files_from_folder(folder_path)\n",
    "\n",
    "# Access pixel values using different lists\n",
    "for i, pixel_values in enumerate(pgm_files_pixel_values):\n",
    "    locals()[f\"train_pixel_values_{i}\"] = pixel_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "folder_path = 'Skullstriped2/t1_icbm_normal_1mm_pn9_rf20/test'\n",
    "pgm_files_pixel_values = read_pgm_files_from_folder(folder_path)\n",
    "\n",
    "# Access pixel values using different lists\n",
    "for i, pixel_values in enumerate(pgm_files_pixel_values):\n",
    "    locals()[f\"test_pixel_values_{i}\"] = pixel_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "folder_path = 'Skullstriped2/t1_icbm_normal_1mm_pn9_rf20/test'\n",
    "pgm_files_pixel_values = read_pgm_files_from_folder(folder_path)\n",
    "\n",
    "# Access pixel values using different lists\n",
    "for i, pixel_values in enumerate(pgm_files_pixel_values):\n",
    "    locals()[f\"test_pixel_values_{i}\"] = pixel_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_pgm_mask(filename):\n",
    "    \"\"\"\n",
    "    Reads a PGM file and returns the image data as a 2D list.\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Skip comments\n",
    "        magic_number = f.readline().strip()\n",
    "        if magic_number != b'P2':\n",
    "            raise ValueError(\"Not a PGM file\")\n",
    "        while True:\n",
    "            line = f.readline().decode('utf-8').strip()\n",
    "            if not line.startswith('#'):\n",
    "                break\n",
    "\n",
    "        # Read the header\n",
    "        width, height = map(int, line.split())\n",
    "        max_val = int(f.readline())\n",
    "\n",
    "        # Read the image data\n",
    "        pixel_values = []\n",
    "        for _ in range(height):\n",
    "            row = map(int, f.readline().split())\n",
    "            pixel_values.extend(row)\n",
    "            \n",
    "       # Convert pixel values greater than 3 to 0\n",
    "        pixel_values = [0 if pixel > 3 else pixel for pixel in pixel_values]\n",
    "\n",
    "        return pixel_values\n",
    "\n",
    "def read_mask_pgm_files_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Reads all PGM files from a folder and returns their data as a list of pixel value lists.\n",
    "    \"\"\"\n",
    "    pgm_files_pixel_values = []\n",
    "    for i, filename in enumerate(os.listdir(folder_path)):\n",
    "        if filename.endswith('.pgm'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            pixel_values = read_pgm_mask(file_path)\n",
    "            pgm_files_pixel_values.append(pixel_values)\n",
    "    return pgm_files_pixel_values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "folder_path = 'Skullstriped2/t1_icbm_normal_1mm_pn9_rf20/train_masks'\n",
    "pgm_files_pixel_values = read_mask_pgm_files_from_folder(folder_path)\n",
    "\n",
    "# Access pixel values using different lists\n",
    "for i, pixel_values in enumerate(pgm_files_pixel_values):\n",
    "    locals()[f\"train_mask_pixel_values_{i}\"] = pixel_values\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "folder_path = 'Skullstriped2/t1_icbm_normal_1mm_pn9_rf20/test_masks'\n",
    "pgm_files_pixel_values = read_mask_pgm_files_from_folder(folder_path)\n",
    "\n",
    "# Access pixel values using different lists\n",
    "for i, pixel_values in enumerate(pgm_files_pixel_values):\n",
    "    locals()[f\"test_mask_pixel_values_{i}\"] = pixel_values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.16.0rc0)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.0-rc0 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow) (2.16.0rc0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (69.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (4.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (1.62.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (3.0.5)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.0-rc0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.0-rc0->tensorflow) (0.42.0)\n",
      "Requirement already satisfied: rich in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.0-rc0->tensorflow) (13.7.0)\n",
      "Requirement already satisfied: namex in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.0-rc0->tensorflow) (0.0.7)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.0-rc0->tensorflow) (0.1.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.0-rc0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.0-rc0->tensorflow) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.0-rc0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.0-rc0->tensorflow) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.0-rc0->tensorflow) (3.5.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.0-rc0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.0-rc0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.0-rc0->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.0-rc0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.0-rc0->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\jksing\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.0-rc0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\S'\n",
      "C:\\Users\\jksing\\AppData\\Local\\Temp\\ipykernel_13792\\3717894292.py:4: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  sys.path.append('G:\\Shruti')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Add the directory containing your module to the Python path\n",
    "sys.path.append('G:\\Shruti')\n",
    "\n",
    "# Now you can import modules from the added directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rbf_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import tensorflow\n",
    "from rbf_keras import kmeans_initializer\n",
    "from keras.optimizers import RMSprop\n",
    "from rbf_keras import rbflayer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1571080\n",
      "1571080\n"
     ]
    }
   ],
   "source": [
    "height = 217\n",
    "width = 181\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for t in range(40):\n",
    "    k = 0  # Reset the index for each file\n",
    "    l = 0  # Reset the index for each file\n",
    "    \n",
    "    # Load pixel values for the current file\n",
    "    train_pixel_values_t = locals().get(f'train_pixel_values_{t}', None)\n",
    "    if train_pixel_values_t is None:\n",
    "        continue  # Skip if data for current file is not found\n",
    "    \n",
    "    # Load mask pixel values for the current file\n",
    "    train_mask_pixel_values_t = locals().get(f'train_mask_pixel_values_{t}', None)\n",
    "    if train_mask_pixel_values_t is None:\n",
    "        continue  # Skip if data for current file is not found\n",
    "    \n",
    "    for i in range(width):\n",
    "        for j in range(height):\n",
    "            rows = []\n",
    "            rows.append(train_pixel_values_t[k])\n",
    "            X_train.append(rows)\n",
    "            k += 1\n",
    "            \n",
    "    for i in range(width):\n",
    "        for j in range(height):\n",
    "            y_train.append(train_mask_pixel_values_t[l])\n",
    "            l += 1\n",
    "            \n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432047\n",
      "432047\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for t in range(11):\n",
    "    k = 0  # Reset the index for each file\n",
    "    l = 0  # Reset the index for each file\n",
    "    \n",
    "    # Load pixel values for the current file\n",
    "    test_pixel_values_t = locals().get(f'test_pixel_values_{t}', None)\n",
    "    if test_pixel_values_t is None:\n",
    "        continue  # Skip if data for current file is not found\n",
    "    \n",
    "    # Load mask pixel values for the current file\n",
    "    test_mask_pixel_values_t = locals().get(f'test_mask_pixel_values_{t}', None)\n",
    "    if test_mask_pixel_values_t is None:\n",
    "        continue  # Skip if data for current file is not found\n",
    "    \n",
    "    for i in range(width):\n",
    "        for j in range(height):\n",
    "            rows = []\n",
    "            rows.append(test_pixel_values_t[k])\n",
    "            X_test.append(rows)\n",
    "            k += 1\n",
    "            \n",
    "    for i in range(width):\n",
    "        for j in range(height):\n",
    "            y_test.append(test_mask_pixel_values_t[l])\n",
    "            l += 1\n",
    "            \n",
    "print(len(X_test))\n",
    "print(len(y_test))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1571080, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'RBFLayer' from 'tensorflow.keras.layers' (c:\\Users\\jksing\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\_tf_keras\\keras\\layers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RBFLayer\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'RBFLayer' from 'tensorflow.keras.layers' (c:\\Users\\jksing\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\_tf_keras\\keras\\layers\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import RBFLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RBFLayer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m histories\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m----> 2\u001b[0m rbfLayer\u001b[38;5;241m=\u001b[39m\u001b[43mRBFLayer\u001b[49m()\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39madd(rbflayer)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RBFLayer' is not defined"
     ]
    }
   ],
   "source": [
    "histories=[]\n",
    "rbfLayer=RBFLayer()\n",
    "model=keras.models.Sequential()\n",
    "model.add(rbflayer)\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(loss='mae',optimizer=RMSprop())\n",
    "\n",
    "history=model.fit(X_train_scaled,y_train,epochs=10,batch_size=16,validation_data=(X_test_scaled,y_test))\n",
    "histories.append(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
