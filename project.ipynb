{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the dimensions of the volume\n",
    "width = 181\n",
    "height = 217\n",
    "depth = 181\n",
    "\n",
    "# Open the input file in binary mode\n",
    "with open(\"BrainWeb/t1_icbm_normal_1mm_pn7_rf20.rawb\", \"rb\") as file:\n",
    "    # Loop through each slice in the volume\n",
    "    for z in range(depth):\n",
    "        # Create a new PGM file for the slice\n",
    "        with open(f'Extracted_files//pgm//t1_icbm_normal_1mm_pn7_rf20//slice_{z}.pgm', \"w+\") as pgm_file:\n",
    "            # Write the PGM file header\n",
    "            pgm_file.write(\"P2\\n\")\n",
    "            pgm_file.write(\"#\\n\")\n",
    "            pgm_file.write(f\"{width} {height}\\n\")\n",
    "            pgm_file.write(\"255\\n\")\n",
    "\n",
    "            # Loop through each row in the slice\n",
    "            for y in range(height):\n",
    "                # Read a row of data from the input file\n",
    "                row_data = file.read(width)  # Each value is 1 byte\n",
    "                # Unpack the row data into a list of integers\n",
    "                values = struct.unpack(f\"{width}B\", row_data)\n",
    "                \n",
    "                scaled_values = [int(v) for v in values]\n",
    "\n",
    "                # Convert each scaled value to decimal and write it to the PGM file\n",
    "                pgm_file.write(\" \".join([str(v) for v in scaled_values]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the input and output directories\n",
    "input_dir = \"Extracted_files/pgm/t1_icbm_normal_1mm_pn7_rf20\"\n",
    "output_dir = \"Extracted_files/jpg/t1_icbm_normal_1mm_pn7_rf20\"\n",
    "\n",
    "# Loop through all of the PGM files in the input directory\n",
    "for file in os.listdir(input_dir):\n",
    "    if file.endswith(\".pgm\"):\n",
    "        # Open the PGM file\n",
    "        with Image.open(os.path.join(input_dir, file)) as img:\n",
    "            # Convert the PGM file to a JPEG file\n",
    "            img.save(os.path.join(output_dir, os.path.splitext(file)[0] + \".jpg\"), \"JPEG\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dfs(x, y, data, skull_mask):\n",
    "    nxt = [(x+1, y), (x-1, y), (x, y+1), (x, y-1)]\n",
    "    for (dx, dy) in nxt:\n",
    "        if 0 <= dx < data.shape[0] and 0 <= dy < data.shape[1] and data[dx, dy] > 0 and not vis[dx][dy]:\n",
    "            vis[dx][dy] = True\n",
    "            skull_mask[dx, dy] = True\n",
    "            dfs(dx, dy, data, skull_mask)\n",
    "\n",
    "# Input and output folders\n",
    "input_folder =  'volumes2\\\\t1_icbm_normal_1mm_pn3_rf20'\n",
    "output_folder = 'skullstriped2\\\\t1_icbm_normal_1mm_pn3_rf20\\\\jpg'\n",
    "\n",
    "# Ensure output folder exists\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Process each image in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        try:\n",
    "            # Read the image\n",
    "            filepath = os.path.join(input_folder, filename)\n",
    "            #print(\"Processing:\", filepath)  # Add debug output\n",
    "            data = io.imread(filepath, as_gray=True).astype(int)\n",
    "\n",
    "\n",
    "            vis = np.zeros_like(data, dtype=bool)\n",
    "            skull_mask = np.zeros_like(data, dtype=bool)\n",
    "\n",
    "            max_count = 0\n",
    "\n",
    "            for i in range(data.shape[0]):\n",
    "                for j in range(data.shape[1]):\n",
    "                    if data[i, j] > 42 and not vis[i][j]:\n",
    "                        temp_skull_mask = np.zeros_like(data, dtype=bool)\n",
    "                        stck = [(i, j)]\n",
    "                        current_count = 0\n",
    "                        while stck:\n",
    "                            x, y = stck.pop()\n",
    "                            temp_skull_mask[x, y] = True\n",
    "                            current_count += 1\n",
    "                            nxt = [(x+1, y), (x-1, y), (x, y+1), (x, y-1)]\n",
    "                            for (dx, dy) in nxt:\n",
    "                                if 0 <= dx < data.shape[0] and 0 <= dy < data.shape[1] and data[dx, dy] > 42 and not vis[dx][dy]:\n",
    "                                    vis[dx][dy] = True\n",
    "                                    stck.append((dx, dy))\n",
    "                        if current_count > max_count:\n",
    "                            max_count = current_count\n",
    "                            skull_mask = temp_skull_mask\n",
    "\n",
    "            # Apply skull mask to the original image to obtain the skull region\n",
    "            skull_image = np.where(skull_mask, data, 0)\n",
    "\n",
    "            # Save the skull-stripped image to the output folder\n",
    "            output_filepath = os.path.join(output_folder, filename)\n",
    "            io.imsave(output_filepath, skull_image.astype(np.uint8))\n",
    "\n",
    "           # print(f\"Processed: {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "print(\"Processing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jpg_to_p2_pgm(input_folder, output_folder):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate through all files in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            # Read the image\n",
    "            input_file = os.path.join(input_folder, filename)\n",
    "            img = cv2.imread(input_file, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Write the image in P2 PGM format\n",
    "            output_file = os.path.join(output_folder, os.path.splitext(filename)[0] + \".pgm\")\n",
    "            with open(output_file, 'w') as f:\n",
    "                f.write(\"P2\\n\")\n",
    "                f.write(\"# P2 PGM file\\n\")\n",
    "                f.write(f\"{img.shape[1]} {img.shape[0]}\\n\")  # Width and height\n",
    "                f.write(\"255\\n\")  # Maximum gray value\n",
    "                for row in img:\n",
    "                    for pixel in row:\n",
    "                        f.write(f\"{pixel} \")\n",
    "                    f.write(\"\\n\")\n",
    "\n",
    "# Example usage:\n",
    "input_folder = 'skullstriped2\\\\t1_icbm_normal_1mm_pn7_rf40\\\\jpg'\n",
    "output_folder = 'skullstriped2\\\\t1_icbm_normal_1mm_pn7_rf40\\\\pgm'\n",
    "jpg_to_p2_pgm(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to split dataset into train and test sets\n",
    "def split_dataset(image_dir, gt_dir, test_size=0.2, random_state=42):\n",
    "    # Get list of image filenames\n",
    "    image_filenames = sorted(os.listdir(image_dir))\n",
    "    \n",
    "    # Get corresponding list of ground truth filenames\n",
    "    gt_filenames = sorted(os.listdir(gt_dir))\n",
    "    \n",
    "    # Split filenames into train and test sets\n",
    "    image_filenames_train, image_filenames_test, gt_filenames_train, gt_filenames_test = train_test_split(\n",
    "        image_filenames, gt_filenames, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    return (image_filenames_train, gt_filenames_train), (image_filenames_test, gt_filenames_test)\n",
    "\n",
    "# Example usage:\n",
    "image_dir = r\"Skullstriped2\\\\t1_icbm_normal_1mm_pn3_rf20\\\\pgm\"\n",
    "gt_dir = r\"volumes2\\\\phantom_1.0mm_normal_crisp\"\n",
    "test_size = 0.2  # 40% of the data will be used for testing\n",
    "random_state = 42  # Random seed for reproducibility\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "(train_files, train_gt_files), (test_files, test_gt_files) = split_dataset(image_dir, gt_dir, test_size, random_state)\n",
    "\n",
    "train_dir = 'Skullstriped2/t1_icbm_normal_1mm_pn3_rf20/train'\n",
    "test_dir = 'Skullstriped2/t1_icbm_normal_1mm_pn3_rf20/test'\n",
    "train_gt_dir = 'Skullstriped2/t1_icbm_normal_1mm_pn3_rf20/train_masks'\n",
    "test_gt_dir = 'Skullstriped2/t1_icbm_normal_1mm_pn3_rf20/test_masks'\n",
    "\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "os.makedirs(train_gt_dir, exist_ok=True)\n",
    "os.makedirs(test_gt_dir, exist_ok=True)\n",
    "\n",
    "# Copy train files to train directory\n",
    "for file_name, gt_file_name in zip(train_files, train_gt_files):\n",
    "    shutil.copyfile(os.path.join(image_dir, file_name), os.path.join(train_dir, file_name))\n",
    "    shutil.copyfile(os.path.join(gt_dir, gt_file_name), os.path.join(train_gt_dir, gt_file_name))\n",
    "\n",
    "# Copy test files to test directory\n",
    "for file_name, gt_file_name in zip(test_files, test_gt_files):\n",
    "    shutil.copyfile(os.path.join(image_dir, file_name), os.path.join(test_dir, file_name))\n",
    "    shutil.copyfile(os.path.join(gt_dir, gt_file_name), os.path.join(test_gt_dir, gt_file_name))\n",
    "\n",
    "# Display the number of files in each split\n",
    "print(\"Number of training files:\", len(train_files))\n",
    "print(\"Number of testing files:\", len(test_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_pgm(filename):\n",
    "    \"\"\"\n",
    "    Reads a PGM file and returns the image data as a 2D list.\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Skip comments\n",
    "        magic_number = f.readline().strip()\n",
    "        if magic_number != b'P2':\n",
    "            raise ValueError(\"Not a PGM file\")\n",
    "        while True:\n",
    "            line = f.readline().decode('utf-8').strip()\n",
    "            if not line.startswith('#'):\n",
    "                break\n",
    "\n",
    "        # Read the header\n",
    "        width, height = map(int, line.split())\n",
    "        max_val = int(f.readline())\n",
    "\n",
    "        # Read the image data\n",
    "        pixel_values = []\n",
    "        for _ in range(height):\n",
    "            row = map(int, f.readline().split())\n",
    "            pixel_values.extend(row)\n",
    "            \n",
    "        max_value = max(pixel_values)\n",
    "        # print(max_value)\n",
    "         # Normalize pixel values to range [0, 1]\n",
    "        pixel_values = [value / max_value for value in pixel_values]\n",
    "\n",
    "        return pixel_values\n",
    "\n",
    "def read_pgm_files_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Reads all PGM files from a folder and returns their data as a list of pixel value lists.\n",
    "    \"\"\"\n",
    "    pgm_files_pixel_values = []\n",
    "    for i, filename in enumerate(os.listdir(folder_path)):\n",
    "        if filename.endswith('.pgm'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            pixel_values = read_pgm(file_path)\n",
    "            pgm_files_pixel_values.append(pixel_values)\n",
    "    return pgm_files_pixel_values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder_path = 'volumes/t1_icbm_normal_1mm_pn0_rf0/train'\n",
    "folder_path = 'Skullstriped2/t1_icbm_normal_1mm_pn3_rf20/train'\n",
    "pgm_files_pixel_values = read_pgm_files_from_folder(folder_path)\n",
    "\n",
    "# Access pixel values using different lists\n",
    "for i, pixel_values in enumerate(pgm_files_pixel_values):\n",
    "    locals()[f\"train_pixel_values_{i}\"] = pixel_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "folder_path = 'Skullstriped2/t1_icbm_normal_1mm_pn3_rf20/test'\n",
    "pgm_files_pixel_values = read_pgm_files_from_folder(folder_path)\n",
    "\n",
    "# Access pixel values using different lists\n",
    "for i, pixel_values in enumerate(pgm_files_pixel_values):\n",
    "    locals()[f\"test_pixel_values_{i}\"] = pixel_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_pgm_mask(filename):\n",
    "    \"\"\"\n",
    "    Reads a PGM file and returns the image data as a 2D list.\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        # Skip comments\n",
    "        magic_number = f.readline().strip()\n",
    "        if magic_number != b'P2':\n",
    "            raise ValueError(\"Not a PGM file\")\n",
    "        while True:\n",
    "            line = f.readline().decode('utf-8').strip()\n",
    "            if not line.startswith('#'):\n",
    "                break\n",
    "\n",
    "        # Read the header\n",
    "        width, height = map(int, line.split())\n",
    "        max_val = int(f.readline())\n",
    "\n",
    "        # Read the image data\n",
    "        pixel_values = []\n",
    "        for _ in range(height):\n",
    "            row = map(int, f.readline().split())\n",
    "            pixel_values.extend(row)\n",
    "            \n",
    "       # Convert pixel values greater than 3 to 0\n",
    "        pixel_values = [0 if pixel > 3 else pixel for pixel in pixel_values]\n",
    "\n",
    "        return pixel_values\n",
    "\n",
    "def read_mask_pgm_files_from_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Reads all PGM files from a folder and returns their data as a list of pixel value lists.\n",
    "    \"\"\"\n",
    "    pgm_files_pixel_values = []\n",
    "    for i, filename in enumerate(os.listdir(folder_path)):\n",
    "        if filename.endswith('.pgm'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            pixel_values = read_pgm_mask(file_path)\n",
    "            pgm_files_pixel_values.append(pixel_values)\n",
    "    return pgm_files_pixel_values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "folder_path = 'Skullstriped2/t1_icbm_normal_1mm_pn3_rf20/train_masks'\n",
    "pgm_files_pixel_values = read_mask_pgm_files_from_folder(folder_path)\n",
    "\n",
    "# Access pixel values using different lists\n",
    "for i, pixel_values in enumerate(pgm_files_pixel_values):\n",
    "    locals()[f\"train_mask_pixel_values_{i}\"] = pixel_values\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "folder_path = 'Skullstriped2/t1_icbm_normal_1mm_pn3_rf20/test_masks'\n",
    "pgm_files_pixel_values = read_mask_pgm_files_from_folder(folder_path)\n",
    "\n",
    "# Access pixel values using different lists\n",
    "for i, pixel_values in enumerate(pgm_files_pixel_values):\n",
    "    locals()[f\"test_mask_pixel_values_{i}\"] = pixel_values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 217\n",
    "width = 181\n",
    "\n",
    "model = SVC(kernel='rbf')\n",
    "\n",
    "for t in range(40):\n",
    "    X_train = []\n",
    "    k = 0\n",
    "    for i in range(width):\n",
    "        for j in range(height):\n",
    "            rows = []\n",
    "            rows.append(locals()[f'train_pixel_values_{t}'][k])\n",
    "            X_train.append(rows)\n",
    "            k += 1\n",
    "            \n",
    "    y_train = []\n",
    "    k = 0\n",
    "    for i in range(width):\n",
    "        for j in range(height):\n",
    "            y_train.append(locals()[f'train_mask_pixel_values_{t}'][k])\n",
    "            k += 1\n",
    "            \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    #Fit the model to the training data\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_accuracy = 0.0\n",
    "\n",
    "for t in range(11):         \n",
    "    X_test=[]\n",
    "    k=0\n",
    "    for i in range(width):\n",
    "        for j in range(height):\n",
    "            rows=[]\n",
    "            rows.append(locals()[f'test_pixel_values_{t}'][k])\n",
    "            X_test.append(rows)\n",
    "            k+=1\n",
    "            \n",
    "    y_test=[]\n",
    "    k=0\n",
    "    for i in range(width):\n",
    "        for j in range(height):\n",
    "            y_test.append(locals()[f'test_mask_pixel_values_{t}'][k])\n",
    "            k+=1\n",
    "            \n",
    "    scaler = StandardScaler() \n",
    "    scaler.fit(X_test)\n",
    "        \n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy for iteration {t+1}: {accuracy}\")\n",
    "    \n",
    "    total_accuracy += accuracy\n",
    "\n",
    "average_accuracy = total_accuracy / 11\n",
    "print(f\"Average Accuracy: {average_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for t in range(11):\n",
    "    k = 0  # Reset the index for each file\n",
    "    l = 0  # Reset the index for each file\n",
    "    \n",
    "    # Load pixel values for the current file\n",
    "    test_pixel_values_t = locals().get(f'test_pixel_values_{t}', None)\n",
    "    if test_pixel_values_t is None:\n",
    "        continue  # Skip if data for current file is not found\n",
    "    \n",
    "    # Load mask pixel values for the current file\n",
    "    test_mask_pixel_values_t = locals().get(f'test_mask_pixel_values_{t}', None)\n",
    "    if test_mask_pixel_values_t is None:\n",
    "        continue  # Skip if data for current file is not found\n",
    "    \n",
    "    for i in range(width):\n",
    "        for j in range(height):\n",
    "            rows = []\n",
    "            rows.append(test_pixel_values_t[k])\n",
    "            X_test.append(rows)\n",
    "            k += 1\n",
    "            \n",
    "    for i in range(width):\n",
    "        for j in range(height):\n",
    "            y_test.append(test_mask_pixel_values_t[l])\n",
    "            l += 1\n",
    "            \n",
    "print(len(X_test))\n",
    "print(len(y_test))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
